def type(main)
    import architecture
    from framework.toolbox.laboratory import Laboratory
    from framework.toolbox.logger import Logger
    from framework.toolbox.stopper import EarlyStopper
    from implementations.$library.toolbox.experiment import $library+FirstUppercase~Experiment as Experiment
    $optimizer+import
    $loss+import
    [$dataset+import]
    from implementations.$library.toolbox.saver import $library+FirstUppercase~ModelSaver as ModelSaver
    $strategy+import

    dataset = $dataset

    experiments = $[$experiment...[, $NL$TAB$TAB$TAB$TAB]$]

    $laboratory

    print("The Lab loss is {}".format(loss))
end

def type(strategy) trigger(import)
    from implementations.$library.toolbox.strategies.$name+Lowercase import $library+FirstUppercase$name+FirstUppercase~Strategy as $name+FirstUppercase~Strategy
end

def type(optimizer) trigger(import)
    from implementations.$library.toolbox.optimizers.$name+Lowercase import $library+FirstUppercase$name~Optimizer as $name~Optimizer
end

def type(loss) trigger(import)
    from implementations.$library.toolbox.losses.$name+Lowercase import $library+FirstUppercase$name~LossFunction as $name~LossFunction
end

def type(dataset) trigger(import)
    from implementations.$library.toolbox.loaders.$name+Lowercase import $library+FirstUppercase$name+FirstUppercase~DatasetLoader as $name+FirstUppercase~DatasetLoader
end

def type(laboratory)
    loss = (Laboratory(name="$laboratoryName",
                           epochs=$epochs,
                           dataset=dataset,
                           architecture=architecture.architecture,
                           experiments=experiments,
                           strategy=$strategy,
                           logger=Logger("$path"))
                .explore())
end

def type(strategy)
    $name+FirstUppercase~Strategy($loss)
end

def type(experiment)
    Experiment("$experimentName",
            $optimizer,
            $loss,
            EarlyStopper($epochs, $patience),
            ModelSaver("$path"))
end

def type(loss)
    $name~LossFunction()
end

def type(dataset)
    $name+FirstUppercase~DatasetLoader("$datasetName", PATH, $batchSize, 42).load($trainProportion, $valProportion, $testProportion)
end

def type(stopper)
    EarlyStopper($epochs, $patiente)
end





def type(optimizer) type(SGD)
    SGDOptimizer(architecture.architecture.parameters(), $lr, $momentum, $dampening, $weight_decay)
end

def type(optimizer) type(Adadelta)
    AdadeltaOptimizer(architecture.architecture.parameters(), $lr, $rho, $eps, $weight_decay)
end

def type(optimizer) type(Adagrad)
    AdagradOptimizer(architecture.architecture.parameters(), $lr, $lr_decay, $eps, $weight_decay)
end

def type(optimizer) type(Adam)
    AdamOptimizerOptimizer(architecture.architecture.parameters(), $lr, ($b0, $b1), $eps, $weight_decay)
end

def type(optimizer) type(Adamax)
    AdamaxOptimizer(architecture.architecture.parameters(), $lr, ($b0, $b1), $eps, $weight_decay)
end

def type(optimizer) type(AdamW)
    AdamWOptimizer(architecture.architecture.parameters(), $lr, ($b0, $b1), $eps, $weight_decay)
end

def type(optimizer) type(AMSGrad)
    AMSGradOptimizer(architecture.architecture.parameters(), $lr, ($b0, $b1), $eps, $weight_decay)
end

def type(optimizer) type(ASGD)
    ASGDOptimizer(architecture.architecture.parameters(), $lr, $alpha, $t0, $weight_decay)
end

def type(optimizer) type(NAdam)
    NAdamOptimizer(architecture.architecture.parameters(), $lr, ($b0, $b1), $eps, $weight_decay)
end

def type(optimizer) type(RProp)
    RPropOptimizer(architecture.architecture.parameters(), $lr, ($eta0, $eta1), ($step0, $step1))
end

def type(optimizer) type(RAdam)
    RAdamOptimizer(architecture.architecture.parameters(), $lr, ($b0, $b1), $eps, $weight_decay)
end

def type(optimizer) type(RMSProp)
    RMSPropOptimizer(architecture.architecture.parameters(), $lr, $alpha, $eps, $weight_decay, $momentum)
end

def type(optimizer) type(SparseAdam)
    SparseAdamOptimizer(architecture.architecture.parameters(), $lr, ($b0, $b1), $eps)
end

def type(optimizer) type(LBFGS)
    LBFGSOptimizer(architecture.architecture.parameters(), $lr, $rho, $eps, $weight_decay)
end